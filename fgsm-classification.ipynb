{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fgsm-classification-adversarial.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOCrIsbP3Q73Y8frz5myze0"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Lb1Tjfly2RpA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600174823190,"user_tz":240,"elapsed":36164,"user":{"displayName":"Seungwon Oh","photoUrl":"https://lh4.googleusercontent.com/-Pykkk6KujHY/AAAAAAAAAAI/AAAAAAAAJnM/cVySNCcOVSA/s64/photo.jpg","userId":"13769519298017181104"}},"outputId":"effde733-0ddb-409e-a799-99431dbd10d3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1t5YfrAtk_3c","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","from PIL import Image\n","import os, glob\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a33LH7cvkwKn","colab_type":"code","colab":{}},"source":["# Helper function to preprocess the image so that it can be inputted in MobileNetV2\n","def get_imagenet_label(probs):\n","  # Helper function to extract str label from probability vector\n","  return decode_predictions(probs, top=1)[0][0] # probs(softmax output) -> [[('n02099712', 'Labrador_retriever', 0.41818538)]]\n","\n","def convert_label_id_to_idx(true_y_id, class_num):\n","  for i in range(class_num):\n","    label = tf.one_hot(i, class_num)\n","    label = tf.reshape(label, (1, class_num))\n","    label = np.array(label)\n","\n","    if true_y_id == get_imagenet_label(label)[0]:\n","      print(get_imagenet_label(label)[1])\n","      break\n","      \n","  return label\n","\n","def preprocess(image, size):\n","  \"\"\"\n","  :params image: image with shape (H,W,C)\n","  :params size: image size that you want to resize\n","  \"\"\"\n","  image = np.array(image) # convert to np array\n","  image = tf.cast(image, tf.float32) # casting pixel values into float numbers\n","  image = tf.image.resize(image, (size[0], size[1])) # resize image size according to the network\n","  image = tf.keras.applications.inception_v3.preprocess_input(image) # normalize pixel values into the range [-1, 1]\n","  image = image[None, ...] # adds batch dimension to the input (H, W, C) -> (B, H, W, C)\n","\n","  return image\n","\n","def calc_grad_fgsm(image, label, model):\n","  \"\"\"\n","  :params image: image with shape (H,W,C)\n","  :params label: one-hot encoded ground truth to calculate the loss\n","  :params model: pre-trained neural network on ImageNet\n","  \"\"\"\n","  loss_object = tf.keras.losses.CategoricalCrossentropy() # loss function for image multi-classification task\n","\n","  with tf.GradientTape() as tape:\n","    tape.watch(image)\n","    prediction = model(image)\n","    loss = loss_object(label, prediction) # comparing prob distribution of ground truth and prediction\n","    gradient = tape.gradient(loss, image) # get the gradients of the loss w.r.t to the input image.\n","  \n","  signed_grad = tf.sign(gradient) # get the sign of the gradients to create the perturbation\n","\n","  return signed_grad\n","\n","def display_images(image, model, description=None): \n","  \"\"\"\n","  :params image: image with shape (H,W,C)\n","  :params model: pre-trained neural network on ImageNet\n","  :params description: one-hot encoded ground truth to calculate the loss\n","  \"\"\"\n","  _, label, confidence = get_imagenet_label(model.predict(image)) # get the label name and the confidence from softmax output predictions\n","  plt.figure()\n","  plt.imshow(image[0]*0.5 + 0.5)\n","\n","  if description is None:\n","    plt.title('Original \\n {} : {:.2f}% Confidence'.format(label, confidence*100))\n","  else:\n","    plt.title('{} \\n {} : {:.2f}% Confidence'.format(description, label, confidence*100))\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDab7E3fklq0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600191517817,"user_tz":240,"elapsed":4117,"user":{"displayName":"Seungwon Oh","photoUrl":"https://lh4.googleusercontent.com/-Pykkk6KujHY/AAAAAAAAAAI/AAAAAAAAJnM/cVySNCcOVSA/s64/photo.jpg","userId":"13769519298017181104"}},"outputId":"7d24d107-3213-43ed-f76b-ece955ebb031"},"source":["epsilons = [0.01, 0.1, 0.15, 0.2] # different values of epsilon\n","descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input') for eps in epsilons]\n","class_num = 1000\n","data_dir = '/content/drive/My Drive/datasets/tiny-imagenet-200/train/n04285008/images'\n","true_y_id = data_dir.split('/')[-2]\n","\n","dirFiles = glob.glob(os.path.join(data_dir, '*.JPEG'))\n","dirFiles.sort()\n","\n","# load the model and freeze the parameters\n","model = tf.keras.applications.InceptionV3(include_top=True, weights='imagenet', classifier_activation='softmax')\n","model.trainable = False\n","\n","# ImageNet labels function\n","decode_predictions = tf.keras.applications.inception_v3.decode_predictions\n","\n","# get ground truth one-hot vector for each image\n","true_y_vector = convert_label_id_to_idx(true_y_id, class_num)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sports_car\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OVvyvGeElbfI","colab_type":"code","colab":{}},"source":["# vanilla FSGM\n","for im_path in dirFiles[:2]:\n","\n","  # preprocess the image so that it could be fed into the model\n","  image = Image.open(im_path)  \n","  x = preprocess(image, (299, 299))\n","\n","  # get the perturbation (signed gradients of loss w.r.t to input image) which will be added to the image \n","  perturbations = calc_grad_fgsm(x, true_y_vector, model) \n","  \n","  # display classification result of original image\n","  display_images(x, model) \n","\n","  # for each epsilon value, add perturbation to original image\n","  for i, eps in enumerate(epsilons):\n","    adv_x = x + eps * perturbations\n","    adv_x = tf.clip_by_value(adv_x, -1, 1)\n","    display_images(adv_x, model, descriptions[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yEQC0LipK-Wv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1F5ICSB-qHzx8sb_tgjIaXMewSp0R1PpV"},"executionInfo":{"status":"ok","timestamp":1600191630884,"user_tz":240,"elapsed":92973,"user":{"displayName":"Seungwon Oh","photoUrl":"https://lh4.googleusercontent.com/-Pykkk6KujHY/AAAAAAAAAAI/AAAAAAAAJnM/cVySNCcOVSA/s64/photo.jpg","userId":"13769519298017181104"}},"outputId":"0ed2734b-74d7-4977-8c40-785f639a62e8"},"source":["epochs = 4\n","\n","for im_path in dirFiles[:5]:\n","\n","  # preprocess the image so that it could be fed into the model\n","  image = Image.open(im_path)  \n","  x = preprocess(image, (299, 299))\n","\n","  # display classification result of original image\n","  display_images(x, model) \n","  \n","  # basic iterative method: run n epochs to find the adversarial image incurring largest loss possible with step size epsilon\n","  for i, eps in enumerate(epsilons):\n","    adv_x = x\n","\n","    for j in range(1, epochs):\n","      print('epoch: {}'.format(j))\n","      perturbations = calc_grad_fgsm(adv_x, true_y_vector, model)  # get the perturbation(signed gradients of loss w.r.t to input image) which will be added to the image\n","      adv_x = adv_x + eps * perturbations\n","\n","    adv_x = tf.clip_by_value(adv_x, -1, 1)\n","    display_images(adv_x, model, descriptions[i])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}