{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"uap-detection.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8ydtH0pdzpsL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1599588809724,"user_tz":240,"elapsed":736,"user":{"displayName":"Seungwon Oh","photoUrl":"https://lh4.googleusercontent.com/-Pykkk6KujHY/AAAAAAAAAAI/AAAAAAAAJnM/cVySNCcOVSA/s64/photo.jpg","userId":"13769519298017181104"}},"outputId":"e64c6acf-830b-4b31-8674-909cee73b7fc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ovhoftk8zzeY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1599588928565,"user_tz":240,"elapsed":5919,"user":{"displayName":"Seungwon Oh","photoUrl":"https://lh4.googleusercontent.com/-Pykkk6KujHY/AAAAAAAAAAI/AAAAAAAAJnM/cVySNCcOVSA/s64/photo.jpg","userId":"13769519298017181104"}},"outputId":"13b15096-c234-4acb-b5b2-ac21bbb698a4"},"source":["# install dependencies:\n","!pip install pyyaml==5.1 pycocotools>=2.0.1\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","# opencv is pre-installed on colab\n","\n","# install detectron2: (Colab has CUDA 10.1 + torch 1.6)\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","assert torch.__version__.startswith(\"1.6\")\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.6.0+cu101 True\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n","Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html\n","Requirement already satisfied: detectron2 in /usr/local/lib/python3.6/dist-packages (0.2.1+cu101)\n","Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.0.1)\n","Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.8)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.2)\n","Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.0.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (7.2.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.3.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n","Requirement already satisfied: fvcore>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.1.post20200716)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->detectron2) (49.6.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->detectron2) (0.29.21)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2) (5.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.18.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.2.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.35.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.12.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.15.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.2.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.31.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.8.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.17.2)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2) (2.0.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (1.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.1.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VtzzSlULz6bb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1599588930851,"user_tz":240,"elapsed":5887,"user":{"displayName":"Seungwon Oh","photoUrl":"https://lh4.googleusercontent.com/-Pykkk6KujHY/AAAAAAAAAAI/AAAAAAAAJnM/cVySNCcOVSA/s64/photo.jpg","userId":"13769519298017181104"}},"outputId":"b2836178-de46-4e8a-ebe4-1fd40569cc28"},"source":["import sys, getopt\n","sys.path.append('/content/drive/My Drive/github/object_detection/universal-master/python')\n","print(sys.path)\n","\n","from pycocotools.coco import COCO\n","import cv2, json, os\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","\n","import detectron2\n","from detectron2 import model_zoo\n","from detectron2.config import get_cfg\n","from detectron2.engine import DefaultTrainer, DefaultPredictor\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","\n","import tensorflow as tf\n","from tensorflow.python.platform import gfile\n","import os.path\n","import matplotlib.pyplot as plt\n","from timeit import time\n","\n","if sys.version_info[0] >= 3:\n","    from urllib.request import urlretrieve\n","else:\n","    from urllib import urlretrieve\n","\n","# from prepare_imagenet_data import preprocess_image_batch, create_imagenet_npy, undo_image_avg\n","from universal_pert import universal_perturbation"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/My Drive/github/object_detection/universal-master/python']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PscNLquO0IQW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599579676740,"user_tz":240,"elapsed":760,"user":{"displayName":"Seungwon Oh","photoUrl":"https://lh4.googleusercontent.com/-Pykkk6KujHY/AAAAAAAAAAI/AAAAAAAAJnM/cVySNCcOVSA/s64/photo.jpg","userId":"13769519298017181104"}}},"source":["def get_config_file(dataset_name, model_file):\n","  cfg = get_cfg()\n","  cfg.merge_from_file(model_zoo.get_config_file(model_file)) # select model of your choice\n","  cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(dataset_name).thing_classes)  # number of classes \n","  \n","  return cfg\n","\n","def coco_images(dataDir, dataType):\n","  \"\"\" load images of specific categories in COCO dataset \n","\n","  :return: list[image]\n","\n","  :param dataDir: str, path to the folder where your annotation files for your videos(frames)\n","  :param dataType: str, dataset split in COCO (train or val)\n","\n","  getAnnIds: Get ann ids that satisfy given filter conditions. \n","  getCatIds: Get cat ids that satisfy given filter conditions. \n","  getImgIds: Get img ids that satisfy given filter conditions. \n","\n","  loadAnns: Load anns with the specified ids. \n","  loadCats: Load cats with the specified ids. \n","  loadImgs: Load imgs with the specified ids. \n","\n","  loadResLoad: algorithm results and create API for accessing them. \n","  showAnnsDisplay: the specified annotations.\n","  \"\"\" \n","\n","  annFile='{}/annotations/instances_{}.json'.format(dataDir, dataType)\n","  imgs = []\n","\n","  # initialize COCO api for instance annotations\n","  coco = COCO(annFile)\n","  # cat_ids = coco.getCatIds()\n","  # cats = coco.loadCats(cat_ids)\n","  \n","  # Define the classes (out of the 81) which you want to get\n","  filterClasses = ['car']\n","\n","  # Get class IDs only corresponding to the filterClasses\n","  catIds = coco.getCatIds(catNms=filterClasses) # finds category['id'] : category['name'] -> find category['id'] matching category['name']\n","\n","  # Get all image ids containing the above Category IDs\n","  # finds annotation[image_id] : category['id'] -> find annotation[category_id] matching category['id'] -> find annotation[image_id] matching annotation[category_id]\n","  imgIds = coco.getImgIds(catIds=catIds) \n","  imgIds.sort()\n","  print(\"Number of images containing classes {}: {}\".format(filterClasses, len(imgIds)))\n","\n","  # load the selected images     \n","  for i in range(20):\n","    print(i)\n","    img_dict = coco.loadImgs(imgIds[i])[0] # get image dict by using image['id'] (we need image['file_name'] to load images of that image['id'])\n","    img = cv2.imread('{}/{}/{}'.format(dataDir, dataType, img_dict['file_name']))\n","    cv2_imshow(img)\n","    imgs.append(img)\n","    \n","  print(\"FINISHED LOADING IMAGES\")\n","  return imgs\n","\n","\n","def extract_roi_labels(imgs, dataset_name, model_file, thresh):\n","  \"\"\"extract labels and boxes for each instance(roi) from the selected images\n","\n","  :output: \n","\n","  :param imgs: the dataset that you want to test your trained detector on (must be registered via func 'register_datasets')\n","  :type imgs: str\n","\n","  :param dataset_name: the dataset that you want to test your trained detector on (must be registered via func 'register_datasets')\n","  :type dataset_name: str\n","\n","  :param model_file: the config file for your object detection model that you want to train on\n","  :type model_file: str\n","\n","  :param thresh: set a custom testing threshold for predicting as positive\n","  :type thresh: int\n","  \"\"\" \n","  rois = []\n","  labels = []\n","\n","  # get dataset and model for prediction\n","  cfg = get_config_file(dataset_name, model_file)\n","  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_file)\n","  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = thresh  \n","  \n","  predictor = DefaultPredictor(cfg)\n","\n","  for im in imgs:\n","    outputs = predictor(im)\n","\n","    # make a prediction on each image and draw predictions on the image\n","    instances = outputs[\"instances\"]\n","    category_instances = instances\n","    \n","    # for each instance boxes\n","    box_list = category_instances.pred_boxes\n","    for inst_box in box_list:\n","\n","      # crop the instance inside the image as a new image for computing universal perturbation\n","      roi = im[int(inst_box[1]):int(inst_box[3]), int(inst_box[0]):int(inst_box[2])]\n","      roi = cv2.resize(roi, (224, 224))\n","      rois.append(roi)\n","\n","    # make labels for each instance\n","    labels.extend(category_instances.pred_classes)\n","  \n","  return cfg, predictor, rois, labels"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZtnjHXRqjnp","colab_type":"code","colab":{}},"source":["def jacobian(y_flat, x, inds, num_classes):\n","    n = num_classes # Not really necessary, just a quick fix.\n","    loop_vars = [\n","         tf.constant(0, tf.int32),\n","         tf.TensorArray(tf.float32, size=n),\n","    ]\n","    _, jacobian = tf.while_loop(\n","        lambda j,_: j < n,\n","        lambda j,result: (j+1, result.write(j, tf.gradients(y_flat[inds[j]], x))),\n","        loop_vars)\n","    \n","    return jacobian.stack()\n","\n","def universal_perturb(cfg, X, predictor, label_originals, str_label_original):\n","    # Default values\n","    device = '/gpu:0'\n","    num_classes = cfg.MODEL.ROI_HEADS.NUM_CLASSES\n","        \n","    with tf.device(device):\n","        persisted_sess = tf.Session()\n","        \n","        def f(image_inp): \n","            outputs = predictor(image_inp)\n","            return outputs['instances'].pred_classes\n","\n","        persisted_sess.graph.get_operations()\n","\n","        persisted_input = persisted_sess.graph.get_tensor_by_name(\"input:0\")\n","        persisted_output = persisted_sess.graph.get_tensor_by_name(\"softmax2_pre_activation:0\")\n","\n","        print('>> Computing feedforward function...')\n","        \n","        file_perturbation = os.path.join('data', 'universal_coco2017val_car_fasterrcnn.npy')\n","        \n","        # if precomputed file doesn't exist, you have to calculate it\n","        if os.path.isfile(file_perturbation) == 0:\n","\n","            print('>> Compiling the gradient tensorflow functions. This might take some time...')\n","            y_flat = tf.reshape(f(image_inp), (-1,))\n","            inds = tf.placeholder(tf.int32, shape=(num_classes,))\n","            dydx = jacobian(y_flat, persisted_input, inds, num_classes)\n","\n","            print('>> Computing gradient function...')\n","            def grad_fs(image_inp, indices): \n","              return persisted_sess.run(dydx, feed_dict={persisted_input: image_inp, inds: indices}).squeeze(axis=1)\n","\n","            # compute universal perturbation v on image X and function f\n","            v = universal_perturbation(X, f, grad_fs, delta=0.2, num_classes=num_classes)\n","\n","            # Save the universal perturbation to your path\n","            np.save(os.path.join(file_perturbation), v)\n","\n","        else:\n","            print('>> Found a pre-computed universal perturbation! Retrieving it from \", file_perturbation')\n","            v = np.load(file_perturbation)\n","\n","        return v\n","\n","        print('>> Testing the universal perturbation on an image')\n","        image_original = X\n","        # Test the perturbation on the image\n","        # Clip the perturbation to make sure images fit in uint8\n","        clipped_v = np.clip(undo_image_avg(image_original[0,:,:,:]+v[0,:,:,:]), 0, 255) - np.clip(undo_image_avg(image_original[0,:,:,:]), 0, 255)\n","        image_perturbed = image_original + clipped_v[None, :, :, :]\n","        label_perturbed = np.argmax(f(image_perturbed), axis=1).flatten()\n","\n","        print(label_original)\n","        print(label_perturbed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PHsyZAYw0OuY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1acevLs_7m3p8wQXr0xosDboFDJ9gcYWV"},"executionInfo":{"status":"error","timestamp":1599583042053,"user_tz":240,"elapsed":73422,"user":{"displayName":"Seungwon Oh","photoUrl":"https://lh4.googleusercontent.com/-Pykkk6KujHY/AAAAAAAAAAI/AAAAAAAAJnM/cVySNCcOVSA/s64/photo.jpg","userId":"13769519298017181104"}},"outputId":"be71dfd0-d44a-4b7b-cf53-498c35349214"},"source":["if __name__ == '__main__':\n","    dataDir='/content/drive/My Drive/datasets/coco'\n","    dataType='val2017'\n","    \n","    # 1. use pycocotools lib to extract images of specific categories in COCO\n","    imgs = coco_images(dataDir, dataType)\n","    \n","    dataset_name = 'coco_2017_val'\n","    conf_file = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n","    thresh = 0.7\n","\n","    # 2. Use Object Detector to extract object instances in those selected images as training images\n","    cfg, predictor, rois, labels = extract_roi_labels(imgs, dataset_name, conf_file, thresh)\n","    \n","    # 3. Use Object Detector to extract object instances in those selected images as training images\n","    universal_perturb(cfg, rois, predictor, labels, MetadataCatalog.get(dataset_name).thing_classes)"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}