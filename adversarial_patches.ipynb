{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adversarial_examples.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NyQdalZne9zS","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nq-zMmmkGKqr","colab_type":"code","colab":{}},"source":["# install dependencies: \n","!pip install pyyaml==5.1 pycocotools>=2.0.1\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","# opencv is pre-installed on colab\n","\n","# install detectron2: (Colab has CUDA 10.1 + torch 1.6)\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","assert torch.__version__.startswith(\"1.6\")\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNL7lymbGOJX","colab_type":"code","colab":{}},"source":["import os\n","# TODO: Change this to your Drive folder location\n","data_dir = '/content/drive/My Drive/github/object_detection/test/'\n","os.chdir(data_dir)\n","!pwd\n","\n","# import some common libraries\n","import numpy as np\n","import cv2, random\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","\n","# You may need to restart your runtime prior to this, to let your installation take effect\n","# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common detectron2 utilities\n","from detectron2.data import MetadataCatalog\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from torchvision import transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3AYXChzGOS5","colab_type":"code","colab":{}},"source":["# select model (get_detector)\n","cfg = get_cfg()\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n","\n","# \"/COCO-InstanceSegmentationn/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n","# \"COCO-Detection/faster_rcnn_R_101_C4_3x.yaml\"\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n","\n","# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n","# \"/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n","# \"COCO-Detection/faster_rcnn_R_101_C4_3x.yaml\"\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n","\n","predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJZO3xnGGOOL","colab_type":"code","colab":{}},"source":["# load images: adversarial images are background images not in the COCO dataset and used as a patch\n","src_r = Image.open('000000001192.jpg')\n","adv_r = Image.open('adversarial2.jpg')  # sample training data from COCO\n","\n","# check our loaded images\n","src.show()\n","adv.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKosBJBrb_Fv","colab_type":"code","colab":{}},"source":["preprocess = transforms.Compose([transforms.Resize(800), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","# resize the adversarial image(src) to match the dimensions of your target image\n","# beware that cv2.resize uses different convention from images in numpy arrays # numpy : (height, width, 3) # image : width x height\n","\n","src = preprocess(src_r)\n","adv = preprocess(adv_r)\n","src = torch.unsqueeze(img, 0)\n","adv = torch.unsqueeze(adv, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkuYyuMZYfbw","colab_type":"code","colab":{}},"source":["# raw predictions\n","outputs = predictor(src)\n","\n","print(outputs[\"instances\"].pred_classes)\n","print(outputs[\"instances\"].pred_boxes)\n","# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(src[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(out.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i6SdUDQbcbXW","colab_type":"text"},"source":["# Experiments"]},{"cell_type":"code","metadata":{"id":"-Q4K2Bu5Tk20","colab_type":"code","colab":{}},"source":["# experiment 1: replace top of the image with differnt background\n","# set grid_num, which is the number of grids that you want to equally divide the height, width of the image\n","grid_num = 12\n","grid_h = height//grid_num\n","print(grid_h)\n","\n","img_list = []\n","\n","for i in range(5):\n","  src_cp = np.copy(src)\n","  src_cp[:grid_h*i,:] = adv[:grid_h*i,:]\n","  cv2_imshow(src_cp)\n","  img_list.append(src_cp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"caWRXgpCTmc7","colab_type":"code","colab":{}},"source":["# experiment 2: replace bottom of the image with differnt background\n","# set grid_num, which is the number of grids that you want to equally divide the height, width of the image\n","grid_num = 12\n","grid_h = height//grid_num\n","print(grid_h)\n","\n","img_list = []\n","\n","for i in range(5):\n","  src_cp = np.copy(src)\n","  src_cp[height-grid_h*i:,:] = adv[height-grid_h*i:,:]\n","  cv2_imshow(src_cp)\n","  img_list.append(src_cp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G1n9szyQUB0T","colab_type":"code","colab":{}},"source":["# experiment 3: \n","# set grid_num, which is the number of grids that you want to equally divide the height, width of the image\n","grid_num = 24\n","grid_h = height//grid_num\n","print(grid_h)\n","\n","img_list = []\n","\n","for i in range(10):\n","  des_cp = np.copy(adv)\n","  des_cp[ymin:int(ymin+2*mod_unit*i),xmin:int(xmin+4*mod_unit*i)] = src[ymin:int(ymin+2*mod_unit*i),xmin:int(xmin+4*mod_unit*i)]\n","  cv2_imshow(des_cp)\n","  img_list.append(des_cp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9F2T5UxcUB_G","colab_type":"code","colab":{}},"source":["# experiment 3: gradually hiding portions of a dog\n","# set grid_num, which is the number of grids that you want to equally divide the height, width of the image\n","grid_num = 24\n","grid = height//grid_num\n","print(grid)\n","\n","img_list = []\n","\n","start_h = 80\n","start_w = 100\n","\n","for i in range(10):\n","  src_cp = np.copy(src)\n","  src_cp[start_h:int(start_h+2*i*grid), start_w:int(start_w+2*i*grid)] = adv[start_h:int(start_h+2*i*grid), start_w:int(start_w+2*i*grid)]\n","  cv2_imshow(src_cp)\n","  img_list.append(src_cp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_ZE24w7UCDq","colab_type":"code","colab":{}},"source":["# experiment 4,5: putting the dog in a different background\n","# set grid_num, which is the number of grids that you want to equally divide the height, width of the image\n","grid_num = 24\n","grid = height//grid_num\n","print(grid)\n","\n","img_list = []\n","\n","start_h = 80\n","start_w = 100\n","\n","for i in range(10):\n","  des_cp = np.copy(adv)\n","  des_cp[start_h:int(start_h+2*i*grid), start_w:int(start_w+2*i*grid)] = src[start_h:int(start_h+2*i*grid), start_w:int(start_w+2*i*grid)]\n","  cv2_imshow(des_cp)\n","  img_list.append(des_cp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6oq3h8GdGr8p","colab_type":"code","colab":{}},"source":["# experiment 6-1: gradual random perturbation of the pixels\n","img_list = []\n","mu = 0\n","sigma = 1\n","\n","src_cp = np.copy(src)\n","img_list.append(src)\n","\n","for i in range(1000001):\n","  rand_h = np.random.randint(low=0, high=src.shape[0])\n","  rand_w = np.random.randint(low=0, high=src.shape[1])\n","  rand_d = np.random.randint(low=0, high=src.shape[2])\n","  \n","  src_cp[rand_h, rand_w, rand_d] = src_cp[rand_h, rand_w, rand_d] + np.random.normal(mu, sigma)\n","  \n","  if i % 200000 == 0:\n","    print(i)\n","    img_list.append(src_cp)\n","    cv2_imshow(src_cp)\n","\n","print('FINISHED')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n_489qtDt_mB","colab_type":"code","colab":{}},"source":["# experiment 6-2: grid random perturbation of the pixels\n","grid_num = 10\n","grid = height//grid_num\n","print(grid)\n","\n","img_list = []\n","mu = 0\n","sigma = 1\n","\n","src_cp = np.copy(src)\n","for _ in range(10):\n","  rand_h = np.random.randint(low=0, high=src.shape[0])\n","  rand_w = np.random.randint(low=0, high=src.shape[1])\n","  src_cp[rand_h, rand_w] = src_cp[rand_h, rand_w] + np.random.normal(mu, sigma)\n","  \n","  img_list.append(src_cp)\n","  cv2_imshow(src_cp)\n","\n","print('FINISHED')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EX1dYgfnugee","colab_type":"code","colab":{}},"source":["# experiment 6-3: entire random perturbation of the pixels\n","img_list = []\n","mu = 10\n","sigma = 5\n","\n","img_list.append(src)\n","src_cp = np.copy(src)\n","src_cp = src_cp + np.random.normal(mu, sigma, (src.shape[0], src.shape[1], src.shape[2]))  \n","img_list.append(src_cp)\n","\n","print('FINISHED')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MdZX1ikSoO6t","colab_type":"code","colab":{}},"source":["# experiment 7: hiding only the eye and nose of a dog\n","img_list = [] # (y,x) = (height, width)\n","\n","left_eye = (180, 200, 215, 240) \n","right_eye = (180, 200, 255, 280) \n","nose = (230, 250, 235, 260) \n","\n","src_cp = np.copy(src)\n","src_cp[left_eye[0]:left_eye[1],left_eye[2]:left_eye[3]] = 0\n","src_cp[right_eye[0]:right_eye[1],right_eye[2]:right_eye[3]] = 0\n","src_cp[nose[0]:nose[1],nose[2]:nose[3]] = 0\n","\n","cv2_imshow(src_cp)\n","img_list.append(src_cp)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LS6I1QRTXh9n","colab_type":"text"},"source":["# Run inference on adversarial examples"]},{"cell_type":"code","metadata":{"id":"vjT8A3MozkBP","colab_type":"code","colab":{}},"source":["for img in img_list:\n","    outputs = predictor(img)\n","    \n","    # look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n","    print(outputs[\"instances\"].pred_classes)\n","    print(outputs[\"instances\"].pred_boxes)\n","\n","    # We can use `Visualizer` to draw the predictions on the image.\n","    v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","\n","    cv2_imshow(out.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]}]}